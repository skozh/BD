{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd02368ea13b64a04b371283ef5424a3f39696477dc8697c632bb26cbef3b68e54b",
   "display_name": "Python 3.7.10 64-bit ('sparkafka': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2368ea13b64a04b371283ef5424a3f39696477dc8697c632bb26cbef3b68e54b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import json\n",
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, StringType, IntegerType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "KAFKA_HOSTS = 'localhost:9092'\n",
    "KAFKA_VERSION = (0, 10, 2)\n",
    "dataDirectory = \"shared_data/bigdata20/followers_info.json/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "    .appName(\"Profile Stream Producer\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendMessage(msg_df, topic):\n",
    "    ds = msg_df\\\n",
    "        .select(F.to_json(F.struct([F.col(c).alias(c)\\\n",
    "         for c in msg_df.columns])).cast(\"string\").alias('value'))\\\n",
    "        .write \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", KAFKA_HOSTS) \\\n",
    "        .option(\"topic\", topic) \\\n",
    "        .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "profile_df = spark.read.json(\"shared_data/bigdata20/followers_info.json/*.json\")\n",
    "posts_df = spark.read.json(\"shared_data/bigdata20/followers_posts_api_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age and sex of the post owner to the posts dataset\n",
    "\n",
    "find_year = F.udf(lambda y: y[-4:] if y else 0, StringType())\n",
    "find_age = F.udf(lambda y: (np.random.randint(15,80)) if y==0 else (datetime.datetime.now().year - y), IntegerType())\n",
    "\n",
    "\n",
    "profile_df = profile_df.withColumn(\"year\",\\\n",
    "                        F.when(F.col('bdate').isNull() | (F.length(F.col('bdate'))<7), '0')\\\n",
    "                        .otherwise(find_year(F.col('bdate'))))\n",
    "profile_df = profile_df.withColumn('age', find_age(profile_df[\"year\"].cast(IntegerType())))\\\n",
    "                        .select(F.col('id').alias('owner_id'), F.col('sex'), F.col('age'))\n",
    "\n",
    "posts_df = posts_df.join(profile_df, \"owner_id\", \"left\")\n",
    "data_df = posts_df.withColumnRenamed('id', 'post_id').na\\\n",
    "                    .drop(subset=['age', 'sex', 'post_id', 'owner_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stopwords\n",
    "\n",
    "stopwords = spark.read.text('shared_data/bigdata20/stopwords.txt')\n",
    "val = stopwords.select('value').collect()\n",
    "wordlist = [ele['value'] for ele in val]\n",
    "x = \",\".join(wordlist)\n",
    "\n",
    "text_df = data_df.select('post_id', 'text').withColumn(\"text\", F.regexp_replace(F.col(\"text\"), \"\\n\", \"\"))\\\n",
    "                    .withColumn(\"unfilteredText\", F.split(\"text\", \" \"))\n",
    "text_df = text_df.withColumn(\"filter_col\", F.lit(x))\\\n",
    "                    .withColumn(\"filter_col\", F.split(\"filter_col\", \",\"))\n",
    "text_df = text_df.withColumn(\"filteredText\", F.array_except(\"unfilteredText\", \"filter_col\"))\\\n",
    "                    .na.drop(subset=['filteredText'])\n",
    "text_df = text_df.select('filteredText').withColumn(\"filteredText\", F.explode(text_df.filteredText))\\\n",
    "                    .withColumn(\"filteredText\", F.regexp_replace(F.col(\"filteredText\"), \",\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send Message\n",
    "\n",
    "data_df = data_df.select(F.col(\"post_id\"), F.col(\"owner_id\"), \\\n",
    "            F.col(\"sex\").cast(\"int\"), F.col(\"age\").cast(\"int\"))\n",
    "\n",
    "sendMessage(data_df.filter(\"sex==1\"), \"male\")\n",
    "sendMessage(data_df.filter(\"sex==2\"), \"female\")\n",
    "sendMessage(data_df.filter(\"age<18\"), \"eighteen\")\n",
    "sendMessage(data_df.filter((data_df.age>=18) & (data_df.age<27)), \"twentyseven\")\n",
    "sendMessage(data_df.filter((data_df.age>=27) & (data_df.age<40)), \"forty\")\n",
    "sendMessage(data_df.filter((data_df.age>=40) & (data_df.age<60)), \"sixty\")\n",
    "sendMessage(data_df.filter(\"age>=60\"), \"senior\")\n",
    "sendMessage(text_df.select('filteredText'), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ]
}