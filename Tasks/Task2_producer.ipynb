{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd02368ea13b64a04b371283ef5424a3f39696477dc8697c632bb26cbef3b68e54b",
   "display_name": "Python 3.7.10 64-bit ('sparkafka': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2368ea13b64a04b371283ef5424a3f39696477dc8697c632bb26cbef3b68e54b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "KAFKA_HOSTS = 'localhost:9092'\n",
    "KAFKA_VERSION = (0, 10, 2)\n",
    "TOPIC = \"profile\"\n",
    "dataDirectory = \"shared_data/bigdata20/followers_info.json/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "    .appName(\"Profile Stream Producer\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "df = spark.read.json(\"shared_data/bigdata20/followers_info.json/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DF\n",
    "\n",
    "kdf = df.select(F.col(\"id\").alias(\"key\"), F.col(\"sex\").alias(\"value\"))\n",
    "ds = kdf \\\n",
    "  .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "  .write \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", KAFKA_HOSTS) \\\n",
    "  .option(\"topic\", TOPIC) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}