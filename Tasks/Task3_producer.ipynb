{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd02368ea13b64a04b371283ef5424a3f39696477dc8697c632bb26cbef3b68e54b",
   "display_name": "Python 3.7.10 64-bit ('sparkafka': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2368ea13b64a04b371283ef5424a3f39696477dc8697c632bb26cbef3b68e54b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import json\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from kafka import KafkaProducer, KafkaConsumer, TopicPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "KAFKA_HOSTS = 'localhost:9092'\n",
    "KAFKA_VERSION = (0, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "    .appName(\"Followers Stream Producer\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Message\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=KAFKA_HOSTS, api_version=KAFKA_VERSION, value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "producer.send(\"test\", \"Hello World!\")\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "followers_df = spark.read.json(\"shared_data/clickhouse_data/followers.json\")\n",
    "posts_df = spark.read.json(\"shared_data/clickhouse_data/posts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df1 = followers_df.select('ctime', 'follower_id', 'profile_id')\n",
    "\n",
    "data_df2 = posts_df.select( 'date', 'comments_count', \\\n",
    "                'from_id', 'likes_count', 'owner_id', 'post_id', \\\n",
    "                'post_type', 'text', 'views_count', 'reposts_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send message\n",
    "\n",
    "def sendMessage(row):\n",
    "    producer = KafkaProducer(bootstrap_servers=KAFKA_HOSTS, api_version=KAFKA_VERSION, value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "    producer.send(topics, row.asDict())\n",
    "    producer.flush()\n",
    "\n",
    "topics = \"followers\"\n",
    "data_df1.rdd.foreach(sendMessage)\n",
    "\n",
    "topics = \"posts\"\n",
    "data_df2.rdd.foreach(sendMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Kafka Test Message\nConsumerRecord(topic='posts', partition=0, offset=0, timestamp=1622530723056, timestamp_type=0, key=None, value=b'{\"date\":\"2012-03-13 00:00:00\",\"comments_count\":-1,\"from_id\":\"78062\",\"likes_count\":2,\"owner_id\":\"-36559458\",\"post_id\":\"5\",\"post_type\":\"post\",\"text\":\"\",\"views_count\":0,\"reposts_count\":0}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=184, serialized_header_size=-1)\n"
     ]
    }
   ],
   "source": [
    "# Consumer test 1\n",
    "\n",
    "consumer = KafkaConsumer('posts', bootstrap_servers=KAFKA_HOSTS, group_id=None, auto_offset_reset ='earliest')\n",
    "tp = TopicPartition('posts',0)\n",
    "print(\"Kafka Test Message\")\n",
    "for message in consumer:\n",
    "    print(message)\n",
    "    if message.offset == consumer.position(tp) - 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Kafka Test Message\n",
      "ConsumerRecord(topic='followers', partition=0, offset=0, timestamp=1622530880617, timestamp_type=0, key=None, value=b'{\"profile_id\":\"328582\",\"follower_id\":\"4652928\",\"ctime\":\"2020-03-07 10:09:50\"}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=77, serialized_header_size=-1)\n"
     ]
    }
   ],
   "source": [
    "# Consumer test 2\n",
    "\n",
    "consumer = KafkaConsumer('followers', bootstrap_servers=KAFKA_HOSTS, group_id=None, auto_offset_reset ='earliest')\n",
    "tp = TopicPartition('followers',0)\n",
    "print(\"Kafka Test Message\")\n",
    "for message in consumer:\n",
    "    print(message)\n",
    "    if message.offset == consumer.position(tp) - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ]
}